{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Qwen2.5-0.5B Chess Model on 108K Dataset\n",
        "\n",
        "This notebook trains a 0.5B parameter model on 108K chess positions with:\n",
        "- Diverse positions (opening, middlegame, endgame)\n",
        "- 8K Lichess puzzles\n",
        "- Material, mobility, and top-5 move evaluations\n",
        "- Stockfish depth 7 analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, platform\n",
        "print(\"CWD:\", os.getcwd())\n",
        "print(\"Python:\", platform.python_version())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "        print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
        "except ImportError:\n",
        "    print(\"torch not installed yet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -U transformers accelerate datasets peft trl python-chess bitsandbytes hf-transfer\n",
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"Initial contents in current directory:\")\n",
        "for name in os.listdir():\n",
        "    print(\"-\", name)\n",
        "\n",
        "# Clone repo if not present\n",
        "if not os.path.exists('train_scripts/train.py'):\n",
        "    if not os.path.exists('sft'):\n",
        "        print('Cloning repo Bot-Rakshit/sft...')\n",
        "        !git clone https://github.com/Bot-Rakshit/sft.git\n",
        "    os.chdir('sft')\n",
        "    print('Changed directory to:', os.getcwd())\n",
        "\n",
        "print('\\nRepo contents:')\n",
        "for name in os.listdir():\n",
        "    print(\"-\", name)\n",
        "\n",
        "assert os.path.exists('train_scripts/train.py'), 'train_scripts/train.py not found'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify training data\n",
        "!wc -l train_data_108k_complete.jsonl\n",
        "!head -n 1 train_data_108k_complete.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Create smaller subset for faster testing (10K examples, ~5-10 min)\n",
        "# Uncomment to use smaller dataset first\n",
        "# !head -n 10000 train_data_108k_complete.jsonl > train_data_10k.jsonl\n",
        "# !wc -l train_data_10k.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Qwen2.5-0.5B with LoRA on full 108K dataset\n",
        "# Optimized for A100 GPU:\n",
        "#   - Batch size 16 with grad_accum 2 = effective batch 32\n",
        "#   - Flash Attention 2 for 2-3x speedup\n",
        "#   - BF16 precision for faster computation\n",
        "# Expected time: ~20-30 minutes on A100\n",
        "!python train_scripts/train.py \\\n",
        "  --model Qwen/Qwen2.5-0.5B-Instruct \\\n",
        "  --data train_data_108k_complete.jsonl \\\n",
        "  --output qwen-chess-0.5b-108k \\\n",
        "  --epochs 1 \\\n",
        "  --batch-size 16 \\\n",
        "  --grad-accum 2 \\\n",
        "  --lr 1.5e-4 \\\n",
        "  --max-seq-length 512 \\\n",
        "  --dtype bf16 \\\n",
        "  --use-flash-attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge LoRA adapter with base model\n",
        "!python train_scripts/merge_model.py \\\n",
        "  --base-model Qwen/Qwen2.5-0.5B-Instruct \\\n",
        "  --adapter qwen-chess-0.5b-108k \\\n",
        "  --output qwen-chess-0.5b-108k-merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the merged model\n",
        "!python train_scripts/test_model.py \\\n",
        "  --model qwen-chess-0.5b-108k-merged \\\n",
        "  --base-model Qwen/Qwen2.5-0.5B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to Google Drive (optional)\n",
        "# Uncomment to mount and save\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r qwen-chess-0.5b-108k-merged /content/drive/MyDrive/\n",
        "\n",
        "# Or create a zip for download\n",
        "!zip -r qwen-chess-0.5b-108k-merged.zip qwen-chess-0.5b-108k-merged\n",
        "print(\"\\nModel saved as qwen-chess-0.5b-108k-merged.zip\")\n",
        "print(\"Download from the Files panel on the left\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Complete!\n",
        "\n",
        "Your model has been trained on 108K positions and is ready for evaluation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
